What is
#  AI SAFETY

by Gustavo Costa

---
## Problem space 
## AI safety

1. Why this matters
2. What is going on
3. What to do

---
## 1
#### Why this matters

---
#### Science

[Press release: The Nobel Prize in Physics 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/physics/2024/press-release/)

[Press release: The Nobel Prize in Chemistry 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/chemistry/2024/press-release/)

---
#### Monopoly

[Three Mile Island nuclear reactor to restart to power Microsoft AI operations | Nuclear power | The Guardian](https://www.theguardian.com/environment/2024/sep/20/three-mile-island-nuclear-plant-reopen-microsoft)

[Google to buy nuclear power for AI datacentres in ‘world first’ deal | Google | The Guardian](https://www.theguardian.com/technology/2024/oct/15/google-buy-nuclear-power-ai-datacentres-kairos-power)

---
#### Surveillance

[Argentina will use AI to ‘predict future crimes’ but experts worry for citizens’ rights | Argentina | The Guardian](https://www.theguardian.com/world/article/2024/aug/01/argentina-ai-predicting-future-crimes-citizen-rights)

---
#### Geopolitics

[The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023 - GOV.UK](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023)

[Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence | The White House](https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/)

---
#### Disruption

- Do you need education?
- Do you need healthcare?
- Do you need employment?
- Do you live in a country?

You are already involved — sorry!

---
## 2
### What is going on

---

![[Pasted image 20241104154925.png]]

[Artificial Intelligence - Global | Statista Market Forecast](https://www.statista.com/outlook/tmo/artificial-intelligence/worldwide#market-size)

---
### Blindspot: science

> Superintelligence will be the most significant development in human history.
> — Sam Altman,  [CEO of OpenAI](https://ia.samaltman.com/)

---
### Blindspot: art

> Music is a language of emotions ... there is no way a program will write anything beautiful ... A grotesque and shameful misestimation of the depth of the human spirit. 
> 
> — Hofstadter apud [Mitchell](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Guide_for_Thinking_Humans), ¶ 5.21

---
#### Discipline: philosophy of science

|              Romanticism              |            Rationalism             |
| :-----------------------------------: | :--------------------------------: |
|                Passion                |               Reason               |
|           Humans > machines           |         Humans < machines          |
| Humans are irrational (complimentary) | Humans are irrational (derogatory) |

---

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | ?              |

---

AI Safety → AI Ethics

---

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | AI Ethics      |
| Facts           | Values         |
| Technology      | Normativity    |

---
### Interdisciplinarity

Wicked problems or just inappropriate tools?

---

Stop trying to fix normative issues with technological solutions

Some things cannot be discovered. They must be decided

---
#### From safety to ethics

Example:

[eleosai.org/papers/20241030\_Taking\_AI\_Welfare\_Seriously\_web.pdf](https://eleosai.org/papers/20241030_Taking_AI_Welfare_Seriously_web.pdf)

[2404.10072](https://arxiv.org/pdf/2404.10072)

---

#### From safety to ethics


[\[2303.12712\] Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)

[Embers of autoregression show how large language models are shaped by the problem they are trained to solve | PNAS](https://www.pnas.org/doi/10.1073/pnas.2322420121)

---

[Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)

[Language (Technology) is Power: A Critical Survey of “Bias” in NLP - ACL Anthology](https://aclanthology.org/2020.acl-main.485/)
 
---

Sociology: [AI Safety Needs Social Scientists](https://distill.pub/2019/safety-needs-social-scientists/)

Environmentalism: [\[2304.03271\] Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models](https://arxiv.org/abs/2304.03271)

Decolonialism:  [The unseen Black faces of AI algorithms](https://www.nature.com/articles/d41586-022-03050-7)

Management:  [Research shows more than 80% of AI projects fail, wasting billions of dollars in capital and resources: Report | Tom's Hardware](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report)

Misinformation: [No evidence that AI disinformation or deepfakes impacted UK, French or European elections results | The Alan Turing Institute](https://www.turing.ac.uk/news/no-evidence-ai-disinformation-or-deepfakes-impacted-uk-french-or-european-elections-results)


---

## 3
### What to do

---
### Synthesis

The first step is taking ethics seriously

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | AI Ethics      |

---
### Synthesis

The second is integration.

|              AI Studies              |
| :----------------------------------: |
| AI safety & ethics & everything else |

---

AI Safety & Ethics → AI studies

---

Philosophy of science → Science studies

[Cultural studies - Wikipedia](https://en.wikipedia.org/wiki/Cultural_studies)
[Science studies - Wikipedia](https://en.wikipedia.org/wiki/Science_studies)
[Gender studies - Wikipedia](https://en.wikipedia.org/wiki/Gender_studies) 
((is an interdisciplinary field))

--- 

Problem: AI has a lot of ethical issues
~~Solution: exclusive focus on within-model, technical solutions~~
Solution: aggregating outside-model, social solutions

---

#### What to do: do not reinvent the wheel

- [Ethics of artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence)
- [Science and technology studies - Wikipedia](https://en.wikipedia.org/wiki/Science_and_technology_studies)
- [Science studies - Wikipedia](https://en.wikipedia.org/wiki/Science_studies)
- [Social informatics - Wikipedia](https://en.wikipedia.org/wiki/Social_informatics)
- [Technology and society - Wikipedia](https://en.wikipedia.org/wiki/Technology_and_society)
- [Social construction of technology - Wikipedia](https://en.wikipedia.org/wiki/Social_construction_of_technology)
- [Algorithmic bias - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_bias)
- [Algorithmic transparency - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_transparency)
- [Algorithmic accountability - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_accountability)
- [Regulation of algorithms - Wikipedia](https://en.wikipedia.org/wiki/Regulation_of_algorithms)
- [Regulation of artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence)
- [Explainable artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)
- [Right to explanation - Wikipedia](https://en.wikipedia.org/wiki/Right_to_explanation)
- [Digital rights - Wikipedia](https://en.wikipedia.org/wiki/Digital_rights)
- [Automated decision-making - Wikipedia](https://en.wikipedia.org/wiki/Automated_decision-making)
- [Machine ethics - Wikipedia](https://en.wikipedia.org/wiki/Machine_ethics)
- [Computer ethics - Wikipedia](https://en.wikipedia.org/wiki/Computer_ethics)
- [Programming ethics - Wikipedia](https://en.wikipedia.org/wiki/Programming_ethics)
- [Fairness (machine learning) - Wikipedia](https://en.wikipedia.org/wiki/Fairness_(machine_learning))

---

#### What to do: do not reinvent the wheel

- [FAccT - ACM Conference on Fairness, Accountability, and Transparency](https://facctconference.org/)
- [Montreal AI Ethics Institute](https://montrealethics.ai/dictionary/)
- [Data and Society](https://datasociety.net/)
- [Home - AI Now Institute](https://ainowinstitute.org/)
- [Ada Lovelace Institute](https://www.adalovelaceinstitute.org/)
- [AI & SOCIETY](https://link.springer.com/journal/146)

---

#### What to do: taxonomies

[dl.acm.org/doi/pdf/10.1145/3531146.3533088](https://dl.acm.org/doi/pdf/10.1145/3531146.3533088)

[\[2406.13843\] Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data](https://arxiv.org/abs/2406.13843)

[Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)

---
### Takeaways

- **Be maximalist**: AI safety + AI ethics + ...
- **Avoid easy labels**: rationalism or social science or ...
- Do not reinvent the wheel

---

What is
#  AI ~~SAFETY~~ ~~ETHICS~~ STUDIES

By Gustavo Costa

---

An interdisciplinary field that tackles problems related to AI using a vartiery of tools -- instead of treating it as a computer science problem to be solved.

- Problems
	- Discrimination
	- Privacy
	- Disinformation
	- Surveillance
	- Automation
	- Factuality
	- Reasoning
	- Understanding
	- Human values
	- Consciousness
	- Algorithmic bias
	- Privacy
	- Surveillance
	- Accountability
	- Alignment
	- Policy
	- Social impact
	- Monopoly
	- Intellectual property
	- Surveillance
	- National security
	- Automation
	- Labour disrupution
	- Productivity
	- Misinformation
	- Deepfakes
	- Resource consumption
	- Environmental impact

---
# References

Slides available on GitHub as a markdown file:

[qr code]

---
#### References

Institutions:
- [FAccT - ACM Conference on Fairness, Accountability, and Transparency](https://facctconference.org/)
- [Montreal AI Ethics Institute](https://montrealethics.ai/dictionary/)
- [Data and Society](https://datasociety.net/)
- [Home - AI Now Institute](https://ainowinstitute.org/)
- [Ada Lovelace Institute](https://www.adalovelaceinstitute.org/)
- [AI & SOCIETY](https://link.springer.com/journal/146)

---
#### References

AI Research:
-  [dl.acm.org/doi/pdf/10.1145/3531146.3533088](https://dl.acm.org/doi/pdf/10.1145/3531146.3533088)
- [\[2406.13843\] Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data](https://arxiv.org/abs/2406.13843)
-  [Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
- [eleosai.org/papers/20241030\_Taking\_AI\_Welfare\_Seriously\_web.pdf](https://eleosai.org/papers/20241030_Taking_AI_Welfare_Seriously_web.pdf)
- [\[2303.12712\] Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)
- [Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
- [Embers of autoregression show how large language models are shaped by the problem they are trained to solve | PNAS](https://www.pnas.org/doi/10.1073/pnas.2322420121)
- [2404.10072](https://arxiv.org/pdf/2404.10072)
- [Language (Technology) is Power: A Critical Survey of “Bias” in NLP - ACL Anthology](https://aclanthology.org/2020.acl-main.485/)
- [AI Safety Needs Social Scientists](https://distill.pub/2019/safety-needs-social-scientists/)
- [\[2304.03271\] Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models](https://arxiv.org/abs/2304.03271)
- [The unseen Black faces of AI algorithms](https://www.nature.com/articles/d41586-022-03050-7)
- [Research shows more than 80% of AI projects fail, wasting billions of dollars in capital and resources: Report | Tom's Hardware](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report)
- [No evidence that AI disinformation or deepfakes impacted UK, French or European elections results | The Alan Turing Institute](https://www.turing.ac.uk/news/no-evidence-ai-disinformation-or-deepfakes-impacted-uk-french-or-european-elections-results)

---
#### References

Techno-optimism
-  [The Intelligence Age](https://ia.samaltman.com/)
-  [Dario Amodei — Machines of Loving Grace](https://darioamodei.com/machines-of-loving-grace)
- [The Techno-Optimist Manifesto | Andreessen Horowitz](https://a16z.com/the-techno-optimist-manifesto/)

---
#### References

AI News
- [Press release: The Nobel Prize in Physics 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/physics/2024/press-release/)
- [Press release: The Nobel Prize in Chemistry 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/chemistry/2024/press-release/)
- [Three Mile Island nuclear reactor to restart to power Microsoft AI operations | Nuclear power | The Guardian](https://www.theguardian.com/environment/2024/sep/20/three-mile-island-nuclear-plant-reopen-microsoft)
- [Google to buy nuclear power for AI datacentres in ‘world first’ deal | Google | The Guardian](https://www.theguardian.com/technology/2024/oct/15/google-buy-nuclear-power-ai-datacentres-kairos-power)
- [Argentina will use AI to ‘predict future crimes’ but experts worry for citizens’ rights | Argentina | The Guardian](https://www.theguardian.com/world/article/2024/aug/01/argentina-ai-predicting-future-crimes-citizen-rights)
- [The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023 - GOV.UK](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023)
- [Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence | The White House](https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/)