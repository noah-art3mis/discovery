What is
#  AI SAFETY

by Gustavo Costa

---

The way we think about AI is wrong

---
## 1
#### Why this matters

---


![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113153544.png]]

![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113153646.png]]


---
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113153852.png]]



---

![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113153955.png]]


---

![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113154301.png]]


---
### Disruption

Education

Healthcare

Employment

Art

War

---

You are already involved

---
## 2
### What is going on

---

> Superintelligence will be the most significant development in human history.
> 
> ...Fixing the climate, establishing a space colony, and the discovery of all of physics...
> 
> — Sam Altman,  [CEO of OpenAI](https://ia.samaltman.com/)

---

> Deep learning works, and we will solve the remaining problems.
> 
> — Sam Altman,  [CEO of OpenAI](https://ia.samaltman.com/)

---
### Blindspot

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | ?              |

note: narrow view. / computer scientists in the last 50 years have a particular framing / things are different now

---

- Discrimination
- Privacy
- Disinformation
- Surveillance
- Automation
- Factuality
- Reasoning
- Understanding
- Human values
- Consciousness
- Algorithmic bias
- Privacy
- Accountability
- Alignment
- Governance
- Social impact
- Monopoly
- Intellectual property
- Surveillance
- National security
- Automation
- Labour disrupution
- Deepfakes
- Resource consumption
- Environmental impact

---

Wicked problems or just inappropriate tools?

---

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | AI Ethics      |
| Facts           | Values         |
| Technical       | Social         |
| Resolution      | Negotiation    |

---

The solution is
### Interdisciplinarity

---

Philosophy: [Debunking Robot Rights Metaphysically, Ethically, and Legally](https://arxiv.org/abs/2404.10072)

Linguistics: [Language (Technology) is Power: A Critical Survey of “Bias” in NLP](https://aclanthology.org/2020.acl-main.485/)

Sociology: [AI Safety Needs Social Scientists](https://distill.pub/2019/safety-needs-social-scientists/)

Ecology: [ Making AI Less "Thirsty"](https://arxiv.org/abs/2304.03271)

Cultural studies:  [The unseen Black faces of AI algorithms](https://www.nature.com/articles/d41586-022-03050-7)

Management:  [80% of AI projects fail](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report)

Political science: [Deepfakes did not impact election](https://www.turing.ac.uk/news/no-evidence-ai-disinformation-or-deepfakes-impacted-uk-french-or-european-elections-results)

---
## 3
### What to do

---

| Natural Science | Social Science |
| --------------- | -------------- |
| AI Safety       | AI Ethics      |

note: confrontational and reductive

---

### Synthesis

|              AI Studies              |
| :----------------------------------: |
| AI safety & ethics & everything else |

---

![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241115113951.png]]
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241115113934.png]]
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241115113920.png]]

---
#### do not reinvent the wheel

- [Ethics of artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence)
- [Science and technology studies - Wikipedia](https://en.wikipedia.org/wiki/Science_and_technology_studies)
- [Science studies - Wikipedia](https://en.wikipedia.org/wiki/Science_studies)
- [Social informatics - Wikipedia](https://en.wikipedia.org/wiki/Social_informatics)
- [Technology and society - Wikipedia](https://en.wikipedia.org/wiki/Technology_and_society)
- [Social construction of technology - Wikipedia](https://en.wikipedia.org/wiki/Social_construction_of_technology)
- [Algorithmic bias - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_bias)
- [Algorithmic transparency - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_transparency)
- [Algorithmic accountability - Wikipedia](https://en.wikipedia.org/wiki/Algorithmic_accountability)
- [Regulation of algorithms - Wikipedia](https://en.wikipedia.org/wiki/Regulation_of_algorithms)
- [Regulation of artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence)
- [Explainable artificial intelligence - Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)
- [Right to explanation - Wikipedia](https://en.wikipedia.org/wiki/Right_to_explanation)
- [Digital rights - Wikipedia](https://en.wikipedia.org/wiki/Digital_rights)
- [Automated decision-making - Wikipedia](https://en.wikipedia.org/wiki/Automated_decision-making)
- [Machine ethics - Wikipedia](https://en.wikipedia.org/wiki/Machine_ethics)
- [Computer ethics - Wikipedia](https://en.wikipedia.org/wiki/Computer_ethics)
- [Programming ethics - Wikipedia](https://en.wikipedia.org/wiki/Programming_ethics)
- [Fairness (machine learning) - Wikipedia](https://en.wikipedia.org/wiki/Fairness_(machine_learning))

---
#### do not reinvent the wheel

![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113161953.png]]
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113162228.png]] 
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113162022.png]] 
![[_LIS/1. Discovery/Assignment 2/static/Pasted image 20241113162259.png]]

---
## 4.
### In conclusion

---

The culture around AI needs to change

note: ai is not computer scientists in their basement doing mathematics and dreaming about the future. This is my proposal

---

What is
# ~~AI SAFETY~~ 
# ~~AI ETHICS~~ 
# AI STUDIES

By Gustavo Costa

---

[Website](https://simulacro.co.uk/) | [LinkedIn](https://www.linkedin.com/in/gustavoarcos/) | [GitHub](https://github.com/noah-art3mis)

Slides: 

![[_LIS/1. Discovery/Assignment 2/static/qr.png]]

https://github.com/noah-art3mis/discovery/blob/main/Capstone1_assessment1_24000114067.md

---
## Resources

---

Institutions:
- [FAccT - ACM Conference on Fairness, Accountability, and Transparency](https://facctconference.org/)
- [Montreal AI Ethics Institute](https://montrealethics.ai/dictionary/)
- [Data and Society](https://datasociety.net/)
- [Home - AI Now Institute](https://ainowinstitute.org/)
- [Ada Lovelace Institute](https://www.adalovelaceinstitute.org/)
- [AI & SOCIETY](https://link.springer.com/journal/146)

---

Books

-  [Artificial Intelligence: A Guide for Thinking Humans (Pelican Books): Amazon.co.uk: Mitchell, Melanie: 9780241404829: Books](https://www.amazon.co.uk/Artificial-Intelligence-Thinking-Humans-Pelican/dp/0241404827)
-  [AI Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference: Amazon.co.uk: Narayanan, Arvind, Kapoor, Sayash: 9780691249131: Books](https://www.amazon.co.uk/Snake-Oil-Artificial-Intelligence-Difference/dp/069124913X)


---

AI Research
-  [dl.acm.org/doi/pdf/10.1145/3531146.3533088](https://dl.acm.org/doi/pdf/10.1145/3531146.3533088)
- [\[2406.13843\] Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data](https://arxiv.org/abs/2406.13843)
-  [Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
- [eleosai.org/papers/20241030\_Taking\_AI\_Welfare\_Seriously\_web.pdf](https://eleosai.org/papers/20241030_Taking_AI_Welfare_Seriously_web.pdf)
- [\[2303.12712\] Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)

---

AI Research
- [Constitutional AI: Harmlessness from AI Feedback \\ Anthropic](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)
- [Embers of autoregression show how large language models are shaped by the problem they are trained to solve | PNAS](https://www.pnas.org/doi/10.1073/pnas.2322420121)
- [2404.10072](https://arxiv.org/pdf/2404.10072)
- [Language (Technology) is Power: A Critical Survey of “Bias” in NLP - ACL Anthology](https://aclanthology.org/2020.acl-main.485/)
- [AI Safety Needs Social Scientists](https://distill.pub/2019/safety-needs-social-scientists/)

---

AI Research
- [\[2304.03271\] Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models](https://arxiv.org/abs/2304.03271)
- [The unseen Black faces of AI algorithms](https://www.nature.com/articles/d41586-022-03050-7)
- [Research shows more than 80% of AI projects fail, wasting billions of dollars in capital and resources: Report | Tom's Hardware](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report)
- [No evidence that AI disinformation or deepfakes impacted UK, French or European elections results | The Alan Turing Institute](https://www.turing.ac.uk/news/no-evidence-ai-disinformation-or-deepfakes-impacted-uk-french-or-european-elections-results)

---

Techno-optimism
-  [The Intelligence Age](https://ia.samaltman.com/)
-  [Dario Amodei — Machines of Loving Grace](https://darioamodei.com/machines-of-loving-grace)
- [The Techno-Optimist Manifesto | Andreessen Horowitz](https://a16z.com/the-techno-optimist-manifesto/)

---

AI News
- [Press release: The Nobel Prize in Physics 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/physics/2024/press-release/)
- [Press release: The Nobel Prize in Chemistry 2024 - NobelPrize.org](https://www.nobelprize.org/prizes/chemistry/2024/press-release/)
- [Three Mile Island nuclear reactor to restart to power Microsoft AI operations | Nuclear power | The Guardian](https://www.theguardian.com/environment/2024/sep/20/three-mile-island-nuclear-plant-reopen-microsoft)
- [Google to buy nuclear power for AI datacentres in ‘world first’ deal | Google | The Guardian](https://www.theguardian.com/technology/2024/oct/15/google-buy-nuclear-power-ai-datacentres-kairos-power)

---

AI News
- [Argentina will use AI to ‘predict future crimes’ but experts worry for citizens’ rights | Argentina | The Guardian](https://www.theguardian.com/world/article/2024/aug/01/argentina-ai-predicting-future-crimes-citizen-rights)
- [The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023 - GOV.UK](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023)
- [Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence | The White House](https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/)